{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "solution_3_efnet_b3_release",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8b600f9dd12d4812a30e1317e34ac4f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_15bde3ac4d924c68a437f30edab30af2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_761d65e973cc49b8ace1f49c70a974fc",
              "IPY_MODEL_4fee9e9875614244ad96d07431aa2462"
            ]
          }
        },
        "15bde3ac4d924c68a437f30edab30af2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "761d65e973cc49b8ace1f49c70a974fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c1b8f4d5b7924df2a1b1f462c9b0f8d9",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 122410125,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 122410125,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0fb7b7c0612047bbb860c8bad8d795bc"
          }
        },
        "4fee9e9875614244ad96d07431aa2462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b511c3177cd54a53a5c021af2e2f0923",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 117M/117M [00:00&lt;00:00, 167MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d24e258503a4db4b9613df2ac018910"
          }
        },
        "c1b8f4d5b7924df2a1b1f462c9b0f8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0fb7b7c0612047bbb860c8bad8d795bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b511c3177cd54a53a5c021af2e2f0923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d24e258503a4db4b9613df2ac018910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2egMjB9E76pb"
      },
      "source": [
        "# Description\n",
        " This solution is based on efficientnet-b3 (net was taken from https://github.com/lukemelas/EfficientNet-PyTorch).\n",
        " \n",
        " The model was trained in the following order:\n",
        " \n",
        " Criterion -MSELoss, optimizer - Adam\n",
        "\n",
        "2 epoch - Learning rate - 0.001\n",
        "\n",
        "4 epoch - Learning rate - 0.0005\n",
        "\n",
        "4 epoch - Learning rate - 0.0001\n",
        "\n",
        "4 epoch - Learning rate - 0.00005\n",
        "\n",
        "4 epoch - Learning rate - 0.00001\n",
        "\n",
        "2 epoch - Learning rate - 0.000005\n",
        "\n",
        "2 epoch - Learning rate - 0.000001\n",
        "\n",
        "Train took a long time on Colab. Due to limit restriction, model weights were saved on some checkpoint and after that training continued on another account.\n",
        "Final model weights were saved in file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7EZ8NSdQwtU"
      },
      "source": [
        "import torch\n",
        "workDir='/home/data/'\n",
        "#imSize=224\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypX_qM1KRBY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37419590-ba08-470e-fed2-3d85ee29200b"
      },
      "source": [
        "# this mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "\n",
        "%cd '/home'\n",
        "!mkdir 'data'\n",
        "%cd '/home/data'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/home\n",
            "/home/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CASL0KLK7VE3"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LMPqopFeRDBt",
        "outputId": "20f015e8-87a6-4006-c9b3-cc7981eb36a1"
      },
      "source": [
        "!pip install --upgrade fastai\n",
        "!pip install -U aicrowd-cli"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/79/e8a87e4c20238e114671314426227db8647d2b42744eab79e0917c59865e/fastai-2.3.1-py3-none-any.whl (194kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 71kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 81kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 92kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 102kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 112kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 122kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 133kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 143kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 153kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 163kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 174kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 184kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.9.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: torch<1.9,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.8.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (19.3.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (20.9)\n",
            "Collecting fastcore<1.4,>=1.3.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b0/f1fbf554e0bf3c76e1bdc3b82eedfe41fcf656479586be38c64421082b1b/fastcore-1.3.20-py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (56.1.0)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.9,>=1.7.0->fastai) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (4.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.4.1)\n",
            "Installing collected packages: fastcore, fastai\n",
            "  Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "Successfully installed fastai-2.3.1 fastcore-1.3.20\n",
            "Collecting aicrowd-cli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/8a/fca67e8c1cb1501a9653cd653232bf6fdebbb2393e3de861aad3636a1136/aicrowd_cli-0.1.6-py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.0MB/s \n",
            "\u001b[?25hCollecting requests-toolbelt<1,>=0.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.8MB/s \n",
            "\u001b[?25hCollecting rich<11,>=10.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/39/fbe8d15f0b017d63701f2a42e4ccb9a73cd4175e5c56214c1b5685e3dd79/rich-10.2.2-py3-none-any.whl (203kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 52.0MB/s \n",
            "\u001b[?25hCollecting requests<3,>=2.25.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: toml<1,>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (0.10.2)\n",
            "Collecting gitpython<4,>=3.1.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/da/6f6224fdfc47dab57881fe20c0d1bc3122be290198ba0bf26a953a045d92/GitPython-3.1.17-py3-none-any.whl (166kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 57.8MB/s \n",
            "\u001b[?25hCollecting tqdm<5,>=4.56.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/8a/34efae5cf9924328a8f34eeb2fdaae14c011462d9f0e3fcded48e1266d1c/tqdm-4.60.0-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 13.0MB/s \n",
            "\u001b[?25hCollecting click<8,>=7.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 16.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions<4.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from rich<11,>=10.0.0->aicrowd-cli) (3.7.4.3)\n",
            "Collecting colorama<0.5.0,>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich<11,>=10.0.0->aicrowd-cli) (2.6.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/92/dfd892312d822f36c55366118b95d914e5f16de11044a27cf10a7d71bbbf/commonmark-0.9.1-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2.10)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.9MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: requests, requests-toolbelt, colorama, commonmark, rich, smmap, gitdb, gitpython, tqdm, click, aicrowd-cli\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: click 8.0.0\n",
            "    Uninstalling click-8.0.0:\n",
            "      Successfully uninstalled click-8.0.0\n",
            "Successfully installed aicrowd-cli-0.1.6 click-7.1.2 colorama-0.4.4 commonmark-0.9.1 gitdb-4.0.7 gitpython-3.1.17 requests-2.25.1 requests-toolbelt-0.9.1 rich-10.2.2 smmap-4.0.0 tqdm-4.60.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSOiRfRcRFQw",
        "outputId": "2bcad242-5214-47a0-9d20-5cae454574f1"
      },
      "source": [
        "API_KEY = '52ab6eb031245b7028158e2f3e993174' #Please enter your API Key from [https://www.aicrowd.com/participants/me]\n",
        "!aicrowd login --api-key $API_KEY"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mAPI Key valid\u001b[0m\n",
            "\u001b[32mSaved API Key successfully!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "327Ri5OzRG7l",
        "outputId": "874d0233-6d95-4f4e-f6d6-87214ee657ce"
      },
      "source": [
        "!aicrowd dataset download --challenge f1-speed-recognition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_submission.csv: 100% 97.8k/97.8k [00:00<00:00, 1.59MB/s]\n",
            "train.csv: 100% 407k/407k [00:00<00:00, 3.67MB/s]\n",
            "train.zip:   0% 0.00/385M [00:00<?, ?B/s]\n",
            "train.zip:  78% 302M/385M [00:03<00:00, 85.5MB/s]\n",
            "train.zip: 100% 385M/385M [00:04<00:00, 83.2MB/s]\n",
            "val.csv: 100% 36.7k/36.7k [00:00<00:00, 1.46MB/s]\n",
            "\n",
            "val.zip:   0% 0.00/37.8M [00:00<?, ?B/s]\n",
            "test.zip: 100% 96.9M/96.9M [00:07<00:00, 13.5MB/s]\n",
            "val.zip: 100% 37.8M/37.8M [00:03<00:00, 11.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_--P-_kRIvu"
      },
      "source": [
        "!rm -rf data\n",
        "!mkdir data\n",
        "\n",
        "!unzip -q train.zip  -d data/train\n",
        "!unzip -q val.zip -d data/val\n",
        "!unzip -q test.zip  -d data/test\n",
        "\n",
        "!mv train.csv data/train.csv\n",
        "!mv val.csv data/val.csv\n",
        "!mv sample_submission.csv data/sample_submission.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kqge6nV7b4a"
      },
      "source": [
        "# Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgoBVfJ-RKpO"
      },
      "source": [
        "# Custom dataset class\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader,RandomSampler\n",
        "from torchvision import transforms as T\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "  def __init__(self,ImageFold,df,transforms):\n",
        "    self.ImageFold=ImageFold\n",
        "    self.df=df\n",
        "    self.trans=transforms\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self,ind):\n",
        "    im=self.load_image(self.df.iloc[ind][0])\n",
        "    speed=self.df.iloc[ind][1]\n",
        "    im=self.trans(im)\n",
        "    return im, speed\n",
        "\n",
        "\n",
        "  def load_image(self,ind):\n",
        "    return Image.open(self.ImageFold+str(self.df.iloc[ind][0])+'.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0_4SOo1RMx5"
      },
      "source": [
        "trainTrans=T.Compose([\n",
        "#        T.Resize(imSize),\n",
        "#        transforms.RandomHorizontalFlip(),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "\n",
        "])\n",
        "\n",
        "df_train=pd.read_csv('data/train.csv')\n",
        "ds_train=ImageDataset(workDir+'data/train/',df_train,trainTrans)\n",
        "dl_train=DataLoader(ds_train,batch_size=32,shuffle=True,num_workers=4)\n",
        "\n",
        "df_val=pd.read_csv('data/val.csv')\n",
        "ds_val=ImageDataset(workDir+'data/val/',df_val,trainTrans)\n",
        "dl_val=DataLoader(ds_val,batch_size=32,shuffle=True,num_workers=4)\n",
        "\n",
        "dataloaders_dict={'train':dl_train,'val':dl_val}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUGmPnZh7leq"
      },
      "source": [
        "# Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiEr7713RP2v"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_loss = 10e30\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            i=0\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    i+=128\n",
        "\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs.float(), torch.reshape(labels,(len(labels),1)).float())\n",
        "\n",
        "                    if(i % 8192 ==0):\n",
        "                      print(loss)\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.detach().item()*len(labels)\n",
        "            epoch_loss = running_loss / (len(dataloaders[phase].dataset))\n",
        "\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_loss)\n",
        "                # statistics\n",
        "\n",
        "            print('{} Loss: {:.4f} '.format(phase, epoch_loss))\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPFfxVpF7sRQ"
      },
      "source": [
        "# EfficientNet training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7avyMlssRSoV"
      },
      "source": [
        "import random\n",
        "\n",
        "import torchvision.models as models\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBSIK0prRTtv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20be8b84-de94-4b3b-ac33-62500854be22"
      },
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/a0/dd40b50aebf0028054b6b35062948da01123d7be38d08b6b1e5435df6363/efficientnet_pytorch-0.7.1.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (1.19.5)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-cp37-none-any.whl size=16443 sha256=b39755b3dc041d8a60548dd1479d328053a7914bca3a8eed7d08b1e9ae9dc035\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/27/aa/c46d23c4e8cc72d41283862b1437e0b3ad318417e8ed7d5921\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOa1bZ7t6Y3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8b600f9dd12d4812a30e1317e34ac4f5",
            "15bde3ac4d924c68a437f30edab30af2",
            "761d65e973cc49b8ace1f49c70a974fc",
            "4fee9e9875614244ad96d07431aa2462",
            "c1b8f4d5b7924df2a1b1f462c9b0f8d9",
            "0fb7b7c0612047bbb860c8bad8d795bc",
            "b511c3177cd54a53a5c021af2e2f0923",
            "7d24e258503a4db4b9613df2ac018910"
          ]
        },
        "outputId": "4cb0490d-c67b-47e1-d62a-6f782993e395"
      },
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "model = EfficientNet.from_pretrained('efficientnet-b5',num_classes = 1)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/weights_ef5_net_adam4.txt'))\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b5-b6417697.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b5-b6417697.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b600f9dd12d4812a30e1317e34ac4f5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=122410125.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded pretrained weights for efficientnet-b5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (_conv_stem): Conv2dStaticSamePadding(\n",
              "    3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "  )\n",
              "  (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_blocks): ModuleList(\n",
              "    (0): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (1): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (2): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (3): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (4): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (5): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (6): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (7): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (8): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(5, 5), stride=[2, 2], groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (9): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (10): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (11): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (12): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (13): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        384, 384, kernel_size=(3, 3), stride=[2, 2], groups=384, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (14): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (15): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (16): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (17): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (18): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (19): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (20): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        768, 768, kernel_size=(5, 5), stride=[1, 1], groups=768, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        768, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (21): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (22): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (23): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (24): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (25): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (26): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (27): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1056, 1056, kernel_size=(5, 5), stride=[2, 2], groups=1056, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (28): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (29): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (30): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (31): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (32): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (33): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (34): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (35): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (36): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(3, 3), stride=[1, 1], groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (37): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        3072, 3072, kernel_size=(3, 3), stride=(1, 1), groups=3072, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        3072, 128, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        128, 3072, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (38): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        3072, 3072, kernel_size=(3, 3), stride=(1, 1), groups=3072, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        3072, 128, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        128, 3072, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "  )\n",
              "  (_conv_head): Conv2dStaticSamePadding(\n",
              "    512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "    (static_padding): Identity()\n",
              "  )\n",
              "  (_bn1): BatchNorm2d(2048, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "  (_dropout): Dropout(p=0.4, inplace=False)\n",
              "  (_fc): Linear(in_features=2048, out_features=1, bias=True)\n",
              "  (_swish): MemoryEfficientSwish()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4Ph_hALsHnX"
      },
      "source": [
        "criterion = nn.MSELoss(reduction='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV4Jlpon6bwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afce6036-be4c-4ca5-f67f-1627e1bda408"
      },
      "source": [
        "num_epochs=3\n",
        "optimizer =torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "criterion = nn.MSELoss(reduction='mean')\n",
        "# Train and evaluate\n",
        "model, hist = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/weights_ef_net_adam1.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/2\n",
            "----------\n",
            "tensor(1126039.3750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(928345., device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(936889.3125, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(455660.5625, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(496136.3750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(389292.8125, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(272891.2500, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(289251.8750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(73087.3594, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(137523.5156, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(46132.3516, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(38502.5234, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(33976.2461, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(43707.4648, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(21662.8145, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(13052.1143, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(29430.6094, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(45079.5547, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(22912.9082, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 365233.9742 \n",
            "tensor(26557.7129, device='cuda:0')\n",
            "val Loss: 24195.2131 \n",
            "\n",
            "Epoch 1/2\n",
            "----------\n",
            "tensor(15004.9551, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(41623.3789, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(14875.4102, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(10762.4434, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(12154.8115, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(12880.5088, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(23775.2578, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(18208.5820, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(10914.1836, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(7584.8901, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(10787.8301, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(5571.7715, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(8155.9551, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(42047.5703, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(7673.6113, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(8544.3506, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(8655.7227, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(12288.6465, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4577.2969, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 17208.3828 \n",
            "tensor(6606.2314, device='cuda:0')\n",
            "val Loss: 7722.5844 \n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "tensor(6238.8237, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(7131.3369, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(10357.3066, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3803.6189, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3876.5813, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4091.0125, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(5196.7378, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(5517.7437, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4542.3687, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4858.5386, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4254.7061, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2551.3186, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6101.1807, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(9434.6543, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6069.4492, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(9532.6426, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(9280.9502, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(7547.0254, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(17375.4629, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 9178.6932 \n",
            "tensor(20476.8008, device='cuda:0')\n",
            "val Loss: 20709.3446 \n",
            "\n",
            "Training complete in 23m 29s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHKijs22RVKT",
        "outputId": "64aef4d6-1e0f-490b-ca3b-8d8c9663a340"
      },
      "source": [
        "num_epochs=3\n",
        "optimizer =torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "criterion = nn.MSELoss(reduction='mean')\n",
        "# Train and evaluate\n",
        "model, hist = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/weights_ef_net_adam1.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/2\n",
            "----------\n",
            "tensor(10052.4648, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(12248.3545, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(11553.3662, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(9536.5107, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6805.2119, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3946.8884, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4307.1206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(11555.7344, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6081.4370, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(9544.8711, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6038.4731, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(7909.7773, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(9623.5273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(7681.7686, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(13583.6074, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6766.0176, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(44085.5547, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(21406.6367, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6607.8628, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 8830.4196 \n",
            "tensor(4242.4668, device='cuda:0')\n",
            "val Loss: 7569.7639 \n",
            "\n",
            "Epoch 1/2\n",
            "----------\n",
            "tensor(2358.8093, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4619.2939, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(5366.6167, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6242.6553, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6365.0977, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(7157.5288, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4030.6250, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4272.6670, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(7887.9902, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(5049.1982, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3701.1465, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(9798.5518, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4727.8506, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2130.8606, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6373.6592, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6868.5479, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6772.4072, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(52808.3047, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3554.6646, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 6916.7339 \n",
            "tensor(2898.0017, device='cuda:0')\n",
            "val Loss: 5475.4497 \n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "tensor(5073.0679, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2010.2195, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2702.3062, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1689.2019, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1967.8163, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(15607.2031, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2933.4807, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2899.6685, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1216.6008, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3636.4316, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1919.4458, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4103.7808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(10727.5586, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3671.7727, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(54774.6758, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(17357.9180, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3085.7314, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(5277.2822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2220.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 4921.7047 \n",
            "tensor(4845.0122, device='cuda:0')\n",
            "val Loss: 5700.8937 \n",
            "\n",
            "Training complete in 23m 31s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4aRVjVlX20H",
        "outputId": "26e7e040-f2ab-436e-b34a-e80e04cf0550"
      },
      "source": [
        "model, hist = train_model(model, dataloaders_dict, criterion, torch.optim.Adam(model.parameters(), lr=0.001), num_epochs=3)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/weights_ef_net_adam.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/2\n",
            "----------\n",
            "tensor(3756.8237, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(29475.7520, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(5094.0674, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6295.3311, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(5429.8594, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4291.2773, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1631.7502, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3508.0024, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4047.3027, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2114.8535, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3424.5869, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3621.0417, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1410.2703, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(8485.8174, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(12587.5020, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1320.9062, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1703.9264, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(11241.8613, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1490.2014, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 4374.1856 \n",
            "tensor(1973.0693, device='cuda:0')\n",
            "val Loss: 4152.1512 \n",
            "\n",
            "Epoch 1/2\n",
            "----------\n",
            "tensor(2710.7930, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1165.8480, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2882.6641, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(7165.0986, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(19554.3711, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3448.8792, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6311.6880, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(11342.7393, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2990.7991, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4124.4336, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1306.5951, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3355.0696, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(9820.8252, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4014.2439, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1952.2258, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(21104.1738, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1686.4866, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(8742.1846, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1790.6304, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 5313.5044 \n",
            "tensor(1568.4878, device='cuda:0')\n",
            "val Loss: 4118.8562 \n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "tensor(5556.8369, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2046.1384, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3694.8086, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2693.8354, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2635.4187, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2626.2944, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3698.8608, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2047.4744, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1072.7540, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(31679.4277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(19148.7070, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2523.5242, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1582.9904, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3232.7832, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1898.1096, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1492.3350, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1769.9034, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1758.5740, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3277.4487, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 3968.3156 \n",
            "tensor(1649.3699, device='cuda:0')\n",
            "val Loss: 3766.6464 \n",
            "\n",
            "Training complete in 23m 37s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjhIEMlydkN9",
        "outputId": "dcaa39d0-14b8-47ea-f29f-6d2a119c55e2"
      },
      "source": [
        "model, hist = train_model(model, dataloaders_dict, criterion, torch.optim.Adam(model.parameters(), lr=0.001), num_epochs=3)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/weights_ef_net_adam.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/2\n",
            "----------\n",
            "tensor(2893.8232, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2540.3550, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2793.8267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1273.9226, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(10621.8945, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2795.8535, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2583.6465, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2635.6509, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2483.7656, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4025.1831, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3121.3335, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(5674.1597, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1881.5269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1358.8624, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4545.9023, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2109.8594, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4350.8042, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4117.4824, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3638.9590, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 3465.6325 \n",
            "tensor(2120.0793, device='cuda:0')\n",
            "val Loss: 3390.0472 \n",
            "\n",
            "Epoch 1/2\n",
            "----------\n",
            "tensor(2549.4038, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(5393.9834, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1171.4164, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4540.5283, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2510.9795, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2191.5342, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(15916.8555, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1048.5153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4479.8350, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3556.8018, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(8044.9575, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(9865.1035, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3819.1584, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2176.3096, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4184.0244, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1476.4612, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3109.7568, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1412.5081, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(7317.6582, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 5286.6663 \n",
            "tensor(2603.8047, device='cuda:0')\n",
            "val Loss: 5209.3836 \n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "tensor(1135.2831, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2307.5278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1328.0654, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(5655.0630, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1303.7634, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1793.4749, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1842.1323, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1715.3237, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3047.8455, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4362.8013, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3897.4045, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2591.6873, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(14122.9609, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3938.4087, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4256.3164, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1841.2444, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2723.5317, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2049.1267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(816.8058, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 3027.3775 \n",
            "tensor(2152.5381, device='cuda:0')\n",
            "val Loss: 4085.4634 \n",
            "\n",
            "Training complete in 23m 32s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP2IA1pSi_1x",
        "outputId": "3e5b79e4-5abb-4d36-dd00-288eed3b88df"
      },
      "source": [
        "model, hist = train_model(model, dataloaders_dict, criterion, torch.optim.Adam(model.parameters(), lr=0.001), num_epochs=3)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/weights_ef_net_adam.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/2\n",
            "----------\n",
            "tensor(944.5835, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2956.5759, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2518.6460, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(921.9926, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1383.4583, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(851.2384, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3022.0774, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1605.8302, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4411.5728, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2044.7336, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2150.5935, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3926.5879, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3243.9272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3387.2542, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1822.9192, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(15316.8076, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2138.0022, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2559.8442, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3333.2493, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 3474.8711 \n",
            "tensor(820.5558, device='cuda:0')\n",
            "val Loss: 3297.7085 \n",
            "\n",
            "Epoch 1/2\n",
            "----------\n",
            "tensor(1170.4021, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1383.9055, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1695.1956, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1008.1459, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3735.6287, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1142.3586, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(849.7682, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1390.8604, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1392.0842, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1132.6704, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4275.1284, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4095.9348, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2161.0684, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(7992.6460, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4371.9341, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3258.5166, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(933.4016, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(17391.5996, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1306.5269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 2976.4617 \n",
            "tensor(3973.2588, device='cuda:0')\n",
            "val Loss: 3105.4816 \n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "tensor(7788.2256, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(5264.4912, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1637.3533, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2236.3511, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1994.0592, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1547.5469, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1526.9318, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1101.6261, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2773.1975, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1560.7758, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1127.9885, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4598.1025, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1120.0510, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(998.5631, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2984.2393, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1079.8763, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1140.3999, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1013.5466, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(756.6921, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 2053.4642 \n",
            "tensor(5339.7554, device='cuda:0')\n",
            "val Loss: 2380.7804 \n",
            "\n",
            "Training complete in 23m 32s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv-Er8sfogKq",
        "outputId": "d8708f38-719b-4070-ab5b-f382fef6e99f"
      },
      "source": [
        "model, hist = train_model(model, dataloaders_dict, criterion, torch.optim.Adam(model.parameters(), lr=0.001), num_epochs=4)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/weights_ef_net_adam__.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/3\n",
            "----------\n",
            "tensor(1369.0421, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2469.8008, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(816.6846, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1022.6912, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1558.9275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1719.9197, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(870.5128, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1680.1464, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4071.4688, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1899.3228, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6213.9316, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(841.3873, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(526.0975, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1590.5012, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1461.2119, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2190.3359, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1171.3905, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1528.1819, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(901.5940, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 1826.5465 \n",
            "tensor(983.1125, device='cuda:0')\n",
            "val Loss: 3399.9513 \n",
            "\n",
            "Epoch 1/3\n",
            "----------\n",
            "tensor(1351.8992, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1063.3196, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2854.6934, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(795.0276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(693.8467, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(600.2297, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1637.3705, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(918.0674, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1069.8854, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(913.1107, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(869.0249, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(762.0253, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(916.9150, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2927.7974, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2661.6038, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6437.0967, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1943.6055, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(581.9954, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3897.4131, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 2101.2526 \n",
            "tensor(1901.5352, device='cuda:0')\n",
            "val Loss: 5335.1697 \n",
            "\n",
            "Epoch 2/3\n",
            "----------\n",
            "tensor(939.7086, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2388.7153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4081.3081, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6266.9683, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2360.7947, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2506.6802, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1271.2316, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2022.6572, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1720.9237, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(826.6438, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3881.1245, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2798.7280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(6873.8945, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(5100.8789, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3835.1125, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(9558.2217, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2525.8452, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2172.6116, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(957.8455, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 4171.2602 \n",
            "tensor(547.7123, device='cuda:0')\n",
            "val Loss: 3448.3992 \n",
            "\n",
            "Epoch 3/3\n",
            "----------\n",
            "tensor(539.2725, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(639.7316, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1056.5583, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1610.9591, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1478.3091, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3785.8281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1036.3065, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1049.7246, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1747.8057, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(869.0558, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2868.8157, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(764.2543, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1374.8667, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1191.6068, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1583.5319, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1037.2563, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1493.5741, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1078.2046, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2143.4243, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 1914.9701 \n",
            "tensor(6556.0278, device='cuda:0')\n",
            "val Loss: 4827.0036 \n",
            "\n",
            "Training complete in 31m 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoInRbze6rFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "993f60d5-9b1d-4bb2-db61-1d08e4cd9ea9"
      },
      "source": [
        "model, hist = train_model(model, dataloaders_dict, criterion, torch.optim.Adam(model.parameters(), lr=0.0003), num_epochs=8)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/weights_ef5_net_adam2.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/7\n",
            "----------\n",
            "tensor(1021.0389, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1839.2002, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(974.2304, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(787.0370, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(957.6029, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(837.1511, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(605.2919, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1114.9446, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(810.6183, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1328.9108, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(821.8687, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1304.4150, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(844.1669, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1700.6825, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(775.7939, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1122.0782, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1049.3840, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(672.8219, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1247.9619, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 1217.7674 \n",
            "tensor(616.5368, device='cuda:0')\n",
            "val Loss: 1703.4802 \n",
            "\n",
            "Epoch 1/7\n",
            "----------\n",
            "tensor(2461.0488, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(884.1342, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(827.2833, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(857.9091, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(598.8275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(575.8914, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(872.0822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(755.2753, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(476.9681, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(529.0455, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(706.0496, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1171.6233, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1085.1633, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(730.7100, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(995.0589, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(700.0463, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(593.3480, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(984.2280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(670.2996, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 988.1423 \n",
            "tensor(4206.1934, device='cuda:0')\n",
            "val Loss: 1703.7215 \n",
            "\n",
            "Epoch 2/7\n",
            "----------\n",
            "tensor(6867.0732, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(586.4392, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(667.1331, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1082.2075, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(400.5692, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(792.4590, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(549.9552, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(612.0175, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1472.9210, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(661.0810, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(434.9098, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(895.2047, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(484.2960, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(641.8995, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1248.6710, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3352.8350, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(382.3703, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(632.3837, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(771.4795, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 968.4276 \n",
            "tensor(2091.2371, device='cuda:0')\n",
            "val Loss: 1392.3256 \n",
            "\n",
            "Epoch 3/7\n",
            "----------\n",
            "tensor(814.3128, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(517.4740, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(689.7659, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(642.2292, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(946.5966, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1230.7294, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(477.6659, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1273.8792, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1346.3496, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1803.0386, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(783.2508, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(915.9884, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1331.4509, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1211.1556, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(756.9850, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(858.8146, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(959.1106, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(886.3307, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(458.6521, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 892.6956 \n",
            "tensor(2397.1587, device='cuda:0')\n",
            "val Loss: 1431.3020 \n",
            "\n",
            "Epoch 4/7\n",
            "----------\n",
            "tensor(361.2756, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(799.1633, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(439.0979, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(974.5688, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(749.9719, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(741.0807, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1098.5482, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(353.4684, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(758.0774, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(522.8766, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1405.2791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1829.0254, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1301.3997, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(514.5048, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(904.0919, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(871.9928, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(490.3075, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(804.5316, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1133.4846, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 889.0178 \n",
            "tensor(194.1868, device='cuda:0')\n",
            "val Loss: 1736.2422 \n",
            "\n",
            "Epoch 5/7\n",
            "----------\n",
            "tensor(481.0308, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1283.6229, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(677.6353, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(760.7186, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(779.5964, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1367.1487, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(938.6368, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1352.8971, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1010.0908, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(783.0493, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(824.5904, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(564.6649, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(595.4376, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(961.6151, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(687.7929, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(565.9882, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(611.3042, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(780.5587, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(724.2666, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 854.6765 \n",
            "tensor(28488.0293, device='cuda:0')\n",
            "val Loss: 1467.2215 \n",
            "\n",
            "Epoch 6/7\n",
            "----------\n",
            "tensor(577.1844, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1276.5446, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(485.7233, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(634.8198, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1475.4982, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(979.6255, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(3637.7529, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(412.4253, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(674.1943, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(670.7603, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(635.9614, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(357.7485, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(736.0706, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1373.4121, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(769.7568, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(751.2875, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(582.5983, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(533.1037, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(821.2677, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 801.7934 \n",
            "tensor(206.9802, device='cuda:0')\n",
            "val Loss: 1561.1108 \n",
            "\n",
            "Epoch 7/7\n",
            "----------\n",
            "tensor(509.8663, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(962.2800, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1014.6615, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(967.9111, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1116.2543, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(811.2045, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(512.4130, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(776.6465, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(324.5875, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1186.7432, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1423.6533, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(464.7187, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(808.8879, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(740.5737, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(359.7856, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(403.4703, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1341.2660, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(817.1873, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(566.6844, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 843.7192 \n",
            "tensor(248.4291, device='cuda:0')\n",
            "val Loss: 1408.3443 \n",
            "\n",
            "Training complete in 62m 50s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJdWX1SvRSjd",
        "outputId": "d8910a5e-9ad3-48b3-e448-b071c09a486e"
      },
      "source": [
        "model, hist = train_model(model, dataloaders_dict, criterion, torch.optim.Adam(model.parameters(), lr=0.0001), num_epochs=8)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/weights_ef5_net_adam3.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/7\n",
            "----------\n",
            "tensor(1893.9414, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(491.1410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(407.0396, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(451.3976, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(591.7089, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(620.9421, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(514.6200, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(685.8617, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1161.3086, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1103.7693, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1507.6575, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(894.1885, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(757.1544, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(611.4003, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(863.7394, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(524.9700, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(954.0220, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(510.5211, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(659.3458, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 849.5421 \n",
            "tensor(9896.1758, device='cuda:0')\n",
            "val Loss: 1439.7559 \n",
            "\n",
            "Epoch 1/7\n",
            "----------\n",
            "tensor(1048.2744, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(357.3139, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(546.5439, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(549.2125, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1157.9297, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(822.9178, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(582.4576, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1010.5164, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(712.7899, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(707.3977, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(411.6434, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(654.1904, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(669.4155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(925.7991, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1545.2308, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(949.5782, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(882.5598, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(454.5476, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(808.0522, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 800.4465 \n",
            "tensor(186.0694, device='cuda:0')\n",
            "val Loss: 1327.2884 \n",
            "\n",
            "Epoch 2/7\n",
            "----------\n",
            "tensor(2975.1421, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1004.7396, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(731.6511, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(418.7595, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(830.8860, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1034.3137, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(638.9575, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(885.4769, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(729.4101, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1326.5658, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(538.0644, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(474.7394, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(443.2044, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(618.4781, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(729.8484, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(426.8477, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(406.6296, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(879.7312, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(444.2820, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 792.6099 \n",
            "tensor(123.6460, device='cuda:0')\n",
            "val Loss: 1356.0864 \n",
            "\n",
            "Epoch 3/7\n",
            "----------\n",
            "tensor(746.5101, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(357.8317, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1103.2001, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(380.1281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(676.4459, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(854.6159, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(562.9914, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(601.1359, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(821.3045, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(682.8887, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(899.6219, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(763.8655, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(987.2762, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(688.3177, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(838.7019, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(648.9834, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(588.0671, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(538.3985, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(839.3175, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 772.8894 \n",
            "tensor(106.5691, device='cuda:0')\n",
            "val Loss: 1420.0434 \n",
            "\n",
            "Epoch 4/7\n",
            "----------\n",
            "tensor(649.2126, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(657.1530, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(572.6566, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(906.6370, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(801.1154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(861.8510, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(439.6890, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2212.3347, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(807.9200, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(522.0710, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(278.9547, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(848.0947, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(588.2655, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(2505.2690, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(823.3610, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(899.9523, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(408.7603, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(843.5858, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(695.9468, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 744.6191 \n",
            "tensor(92.9794, device='cuda:0')\n",
            "val Loss: 1362.1422 \n",
            "\n",
            "Epoch 5/7\n",
            "----------\n",
            "tensor(520.7456, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(579.5954, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(629.9301, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(466.5580, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(471.4761, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(703.1233, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(396.1379, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1097.0435, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(861.3225, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(748.8499, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(732.9205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(656.7502, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1266.3496, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(380.9953, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(508.6892, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(902.3823, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(554.6791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(876.3474, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(684.3326, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 732.9475 \n",
            "tensor(347.4896, device='cuda:0')\n",
            "val Loss: 1349.7754 \n",
            "\n",
            "Epoch 6/7\n",
            "----------\n",
            "tensor(627.1010, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(681.6164, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(527.7015, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(849.9796, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(456.8881, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(623.4297, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(346.1087, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(509.2261, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(679.1948, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1266.7844, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(726.9844, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1187.8613, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(633.9756, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(825.3547, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1149.2385, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(747.3878, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(418.1491, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(777.0673, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(649.3445, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 702.8133 \n",
            "tensor(168.9305, device='cuda:0')\n",
            "val Loss: 1425.4564 \n",
            "\n",
            "Epoch 7/7\n",
            "----------\n",
            "tensor(724.1061, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(981.2323, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(382.1414, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(477.4351, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(343.7090, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(506.9417, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1084.4341, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(611.7816, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(499.7361, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1124.6199, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(419.9083, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1132.3693, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(974.0189, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(910.7921, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(699.8044, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1127.5087, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1593.0378, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1084.7552, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1207.8103, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 711.7769 \n",
            "tensor(91.4766, device='cuda:0')\n",
            "val Loss: 1416.2851 \n",
            "\n",
            "Training complete in 62m 51s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzNvoxtEYxAo",
        "outputId": "a8251d2c-a36c-4ebb-aaf0-0fd0d8814ec0"
      },
      "source": [
        "model, hist = train_model(model, dataloaders_dict, criterion, torch.optim.Adam(model.parameters(), lr=0.00003), num_epochs=8)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/weights_ef5_net_adam4.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/7\n",
            "----------\n",
            "tensor(557.4513, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1275.9635, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1142.1570, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(701.0946, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(473.2738, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(707.8235, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(559.0863, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(639.2803, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(572.5847, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(675.5094, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1098.4247, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(776.4652, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(883.4783, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(604.8850, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(305.4053, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1144.2603, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1254.9189, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(715.5989, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(552.5999, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 779.6201 \n",
            "tensor(29519.7871, device='cuda:0')\n",
            "val Loss: 1324.6370 \n",
            "\n",
            "Epoch 1/7\n",
            "----------\n",
            "tensor(550.5531, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(646.0627, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1208.2349, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(386.6393, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(973.1709, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1067.4120, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1206.8718, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(694.6691, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(605.0795, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(581.8184, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(872.8865, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(323.5513, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(479.0033, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(712.5197, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(848.7914, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(340.4974, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(751.3362, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(582.8821, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(762.6750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 759.9753 \n",
            "tensor(105.5128, device='cuda:0')\n",
            "val Loss: 1379.5874 \n",
            "\n",
            "Epoch 2/7\n",
            "----------\n",
            "tensor(1067.5759, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(718.7767, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(449.7345, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(564.8746, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(493.0490, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(641.6085, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(705.7722, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(545.9653, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(615.9921, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(769.7947, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(545.8456, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(704.1823, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(690.9713, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(424.7306, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(776.8778, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(756.0140, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1251.7290, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(516.2026, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(879.1694, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 764.1586 \n",
            "tensor(2414.6880, device='cuda:0')\n",
            "val Loss: 1367.2359 \n",
            "\n",
            "Epoch 3/7\n",
            "----------\n",
            "tensor(982.4999, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(723.8063, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(479.2018, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(520.7103, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(638.4678, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(870.0285, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(361.3197, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(802.6613, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(359.7191, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(311.7228, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1256.6506, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(529.8437, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(813.0436, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(628.1933, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(401.0801, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(649.9983, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1080.6089, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(789.9310, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(963.3047, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 730.0842 \n",
            "tensor(103.3152, device='cuda:0')\n",
            "val Loss: 1347.2068 \n",
            "\n",
            "Epoch 4/7\n",
            "----------\n",
            "tensor(848.6259, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(758.6728, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(418.3472, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(583.7791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(649.3426, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(476.7333, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1369.1906, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1011.3356, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(587.9127, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(346.0956, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(761.3312, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(590.2959, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(905.4476, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(610.3942, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(706.6362, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(667.5505, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(713.1520, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(913.5762, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1111.5591, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 739.3353 \n",
            "tensor(399.8507, device='cuda:0')\n",
            "val Loss: 1322.6124 \n",
            "\n",
            "Epoch 5/7\n",
            "----------\n",
            "tensor(785.0142, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(399.1312, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(446.4752, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(462.2217, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(310.0354, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(511.7921, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(414.0130, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(488.4758, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1072.3000, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(415.2217, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(459.3622, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(541.4727, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(378.8484, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(908.4778, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(559.8579, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(984.0187, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(849.6495, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(448.7370, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(602.8341, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 712.7997 \n",
            "tensor(127.7019, device='cuda:0')\n",
            "val Loss: 1327.9564 \n",
            "\n",
            "Epoch 6/7\n",
            "----------\n",
            "tensor(875.3263, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(605.9894, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(313.8354, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1012.6488, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(471.2280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(924.4403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(603.6794, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(300.9218, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(663.2133, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(478.0306, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(887.3363, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1212.9299, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(765.0774, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(730.8415, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(549.9520, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(404.9858, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(863.1225, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(395.0944, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(910.2090, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 714.0271 \n",
            "tensor(131.5949, device='cuda:0')\n",
            "val Loss: 1311.3705 \n",
            "\n",
            "Epoch 7/7\n",
            "----------\n",
            "tensor(692.8297, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1255.2542, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(612.1259, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(486.5991, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(664.1965, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1277.3528, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(924.0161, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(581.8583, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(887.3478, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(870.4787, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(425.2536, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(899.5668, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(712.8131, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(652.1807, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(429.2379, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(745.0189, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1241.1256, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(465.5525, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1108.3672, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 707.1351 \n",
            "tensor(66.7626, device='cuda:0')\n",
            "val Loss: 1347.7592 \n",
            "\n",
            "Training complete in 62m 36s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFxBhSDTY0fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b394cb84-c508-47ec-fcce-f6be0514bac7"
      },
      "source": [
        "model, hist = train_model(model, dataloaders_dict, criterion, torch.optim.Adam(model.parameters(), lr=0.00001), num_epochs=5)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/weights_ef5_net_adam5.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/4\n",
            "----------\n",
            "tensor(474.4205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(520.7783, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(691.4502, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1915.4984, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(981.7435, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(660.6892, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(725.6124, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(658.2329, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(616.6148, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(665.7450, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(538.1611, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(398.0583, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1031.8822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(390.9847, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(505.6226, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(610.5330, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(723.2950, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(615.5419, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(757.6169, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 699.4458 \n",
            "tensor(81.6333, device='cuda:0')\n",
            "val Loss: 1309.3945 \n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "tensor(904.9321, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(679.7383, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(835.8688, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(737.5471, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(660.0707, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(538.5067, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(625.6597, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(345.7386, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(626.9946, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(785.5850, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(113.2039, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(429.0422, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(745.8002, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(587.3675, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(443.0291, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(672.5412, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(410.6427, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(551.1369, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(424.3795, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 692.0891 \n",
            "tensor(27287.0586, device='cuda:0')\n",
            "val Loss: 1327.4097 \n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "tensor(617.1632, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(405.6962, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1203.4521, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(763.0702, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(777.2101, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(887.4746, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(4175.7495, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(721.0527, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(816.9531, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(534.9386, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(709.9523, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(613.1090, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(319.8206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(498.8016, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(766.7651, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(605.1559, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(965.1078, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(649.0719, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(422.6246, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 698.7366 \n",
            "tensor(1426.4725, device='cuda:0')\n",
            "val Loss: 1332.8609 \n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "tensor(810.1728, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(469.7860, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1107.9319, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(838.5443, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(393.2704, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(452.2599, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(864.8928, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1188.9148, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(689.8696, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(573.8225, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(654.5557, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(837.8419, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(690.6844, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(330.3257, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(496.6655, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(650.8167, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(554.5222, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(676.4238, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(578.6619, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 689.0244 \n",
            "tensor(162.0581, device='cuda:0')\n",
            "val Loss: 1317.7533 \n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "tensor(398.6326, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(548.9901, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(580.1676, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(533.1057, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(504.1043, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(588.8623, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(655.1155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(644.3137, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(983.9981, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1054.2576, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(560.1362, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(835.9634, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(892.5691, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(915.7896, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(839.8195, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1182.6750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1090.5099, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(521.6654, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(490.2231, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 691.3856 \n",
            "tensor(3767.6106, device='cuda:0')\n",
            "val Loss: 1326.4231 \n",
            "\n",
            "Training complete in 72m 37s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_8L4dLsY6-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7299514b-5959-452a-cbef-8ee1650a58fe"
      },
      "source": [
        "model, hist = train_model(model, dataloaders_dict, criterion, torch.optim.Adam(model.parameters(), lr=0.000003), num_epochs=5)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/weights_ef5_net_adam6.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/4\n",
            "----------\n",
            "tensor(459.1544, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(959.9667, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(755.1567, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(504.5496, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(783.6774, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(405.2543, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1557.6870, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(697.2979, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(538.7745, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(662.6500, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(566.3698, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(542.2593, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(756.8997, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(754.3699, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(590.2037, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(314.1022, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(851.4091, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(682.4498, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(914.5414, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 715.5992 \n",
            "tensor(143.4515, device='cuda:0')\n",
            "val Loss: 1318.2458 \n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "tensor(608.9588, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(453.4824, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(743.2053, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(604.9442, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(890.0687, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(680.3484, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(692.8219, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(900.7077, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(522.8530, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(292.3668, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(496.1448, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(454.4898, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(846.2621, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(690.9159, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1043.9785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(411.4757, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(782.8490, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(407.6249, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(423.6574, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 696.7618 \n",
            "tensor(223.3346, device='cuda:0')\n",
            "val Loss: 1313.4023 \n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "tensor(688.7407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(388.4598, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(705.8300, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(558.8851, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(825.5137, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(537.5566, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(464.5101, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(700.2145, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1293.0186, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(452.5471, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(969.3383, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(274.2343, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1131.5858, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(373.1921, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(882.5729, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1240.2336, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(490.7855, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(797.4427, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1054.9485, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 695.4912 \n",
            "tensor(4549.1040, device='cuda:0')\n",
            "val Loss: 1322.9624 \n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "tensor(988.7066, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1485.9719, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(987.4691, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(593.1062, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(704.2724, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(388.2776, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(443.7773, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(373.9128, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(715.3870, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(896.2750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(742.5311, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(753.6001, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(483.8671, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(747.6678, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(698.3331, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(598.5282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(732.1938, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(696.3341, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(649.3403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 699.6668 \n",
            "tensor(166.1459, device='cuda:0')\n",
            "val Loss: 1324.3819 \n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "tensor(695.8196, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(351.6412, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1042.9663, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(433.0515, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(708.3881, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(896.5139, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(492.7296, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(703.6683, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(685.7272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(773.7471, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(423.0814, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(507.9961, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(546.0551, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(714.9069, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(649.1038, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(673.2117, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1611.0286, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(377.8221, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(489.1741, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 703.2385 \n",
            "tensor(241.1334, device='cuda:0')\n",
            "val Loss: 1317.6488 \n",
            "\n",
            "Training complete in 72m 40s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqYwB1quY_FG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ea52c1-403f-402a-f3c2-3d9f424303a7"
      },
      "source": [
        "model, hist = train_model(model, dataloaders_dict, criterion, torch.optim.Adam(model.parameters(), lr=0.000001), num_epochs=5)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/weights_ef5_net_adam6.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/4\n",
            "----------\n",
            "tensor(374.0327, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(840.9709, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1089.3677, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(248.8978, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(857.8651, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(619.9756, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(376.7505, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(801.1678, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(324.1050, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(639.1308, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(641.3213, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(631.1763, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(369.9946, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(892.0739, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(471.9645, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(931.4033, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(542.2040, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(263.9974, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1062.1045, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 707.5611 \n",
            "tensor(173.5317, device='cuda:0')\n",
            "val Loss: 1325.3995 \n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "tensor(789.0584, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(656.5427, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(878.6625, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1635.8201, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(423.2480, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1028.0320, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(395.3095, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(779.4139, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(641.7259, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(466.6595, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(836.4004, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1159.6316, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(422.2290, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(519.6357, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(500.0964, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1351.2784, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1635.4469, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(403.1234, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(986.4741, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 699.6118 \n",
            "tensor(69.8518, device='cuda:0')\n",
            "val Loss: 1326.8070 \n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "tensor(410.2752, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(775.6812, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(922.7560, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(909.2839, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(577.0360, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(715.2623, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(444.8695, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(699.2564, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(861.4148, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(891.0555, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(377.3217, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(395.7995, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(456.5496, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(705.6714, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(971.9423, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(517.2520, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(627.2681, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(947.3318, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(457.4852, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 696.4207 \n",
            "tensor(205.4798, device='cuda:0')\n",
            "val Loss: 1319.8425 \n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "tensor(517.2361, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(529.9508, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(995.4133, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(529.1346, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1294.5020, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(374.8243, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(675.4749, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(545.4537, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(826.8840, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(421.8890, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(857.6523, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(286.3632, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(604.4668, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(770.2843, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(739.8259, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(725.3483, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1055.2581, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(751.5704, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(911.6670, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 686.7360 \n",
            "tensor(114.2301, device='cuda:0')\n",
            "val Loss: 1322.7420 \n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "tensor(582.1881, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(776.2437, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(429.7910, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(840.8004, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(865.9403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(517.0648, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(345.3684, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(600.4232, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(361.8311, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(1064.9000, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(740.4256, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(538.8967, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(275.7245, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(582.6667, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(471.8724, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(418.3882, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(667.7050, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(716.4990, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(653.1924, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "train Loss: 697.6444 \n",
            "tensor(185.6894, device='cuda:0')\n",
            "val Loss: 1318.7830 \n",
            "\n",
            "Training complete in 72m 38s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPQ4HMI87x00"
      },
      "source": [
        "# Prediction and data uploading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKNstLsPQhTm"
      },
      "source": [
        "A=[[i for i in range(10000)],[0]*10000]\n",
        "df=pd.DataFrame(A).transpose()\n",
        "df.columns=['ImageID','label']\n",
        "i=0\n",
        "for f in os.listdir('data/test/'):\n",
        "  im=Image.open('data/test/'+f)\n",
        "  a=trainTrans(im)\n",
        "  tens=torch.reshape(a,(1,3,a.size(1),a.size(2)))\n",
        "  inputs = tens.to(device)\n",
        "  outputs = (model(inputs).detach().cpu().numpy())\n",
        "  df.iloc[int(f.split('.')[0]),1]=outputs[0][0]\n",
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/submission.csv',index=False)\n",
        "!aicrowd submission create -c f1-speed-recognition -f '/content/drive/MyDrive/Colab Notebooks/submission.csv'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}