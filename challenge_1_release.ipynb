{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"challenge_1_release.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyM2qn/FkgsS0VDZN5SvdznS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Wedj_hCsGSWL"},"source":["#Description \n","\n","For this issue vgg16 model was taken. This solution uses pytorch"]},{"cell_type":"markdown","metadata":{"id":"DGI7VC3DFu5i"},"source":["# Downloading data"]},{"cell_type":"code","metadata":{"id":"vhN_YNlBT7AH"},"source":["# this mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7XTe6wX710fN"},"source":["import os\n","os.mkdir('/home/data/')\n","%cd '/home/data/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Rgf2MziVJJb"},"source":["!pip install --upgrade fastai \n","!pip install aicrowd-cli"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YnhTD-xWVBC5"},"source":["API_KEY = '52ab6eb031245b7028158e2f3e993174' #Please enter your API Key from [https://www.aicrowd.com/participants/me]\n","!aicrowd login --api-key $API_KEY"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HI6HOHU7VGgX"},"source":["!aicrowd dataset download --challenge f1-team-classification -j 3 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5fW2sE_dVqpK"},"source":["!rm -rf data\n","!mkdir data\n","\n","!unzip train.zip  -d data/train\n","!unzip val.zip -d data/val\n","!unzip test.zip  -d data/test\n","\n","!mv train.csv data/train.csv\n","!mv val.csv data/val.csv\n","!mv sample_submission.csv data/sample_submission.csv"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L2Mb6yZznUHA"},"source":["#import modules and define custom dataset class"]},{"cell_type":"code","metadata":{"id":"skoRPCWhV1Ho"},"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset,DataLoader,RandomSampler\n","from torchvision import transforms\n","import torch.optim as optim\n","import torchvision.models as models\n","\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","import time\n","import os\n","import copy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mxHI8KLqVbiQ"},"source":["class ImageDataset(Dataset):\n","  def __init__(self,ImageFold,df,lblDict,transforms):\n","    self.ImageFold=ImageFold\n","    self.df=df\n","    self.lblDict=lblDict\n","    self.trans=transforms\n","\n","  def __len__(self):\n","    return len(self.df)\n","\n","  def __getitem__(self,ind):\n","    im=self.load_image(self.df.iloc[ind][0])\n","    lbl=self.lblDict[self.df.iloc[ind][1]]\n","    im=self.trans(im)\n","    return im, lbl\n","\n","\n","  def load_image(self,ind):\n","    return Image.open(self.ImageFold+str(self.df.iloc[ind][0])+'.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"01BH2VRDnk9l"},"source":["Prepare data: augmentation with transforms and load with DataLoader"]},{"cell_type":"code","metadata":{"id":"JeUst3CJog1w"},"source":["data_transform = transforms.Compose([\n","        transforms.Resize(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                             std=[0.229, 0.224, 0.225])\n","    ])\n","\n","df_train=pd.read_csv('data/train.csv')\n","df_val=pd.read_csv('data/val.csv')\n","\n","ds_train=ImageDataset('data/train/',df_train,{'redbull' : 0 , 'mercedes' : 1},transforms=data_transform)\n","ds_val=ImageDataset('data/val/',df_val,{'redbull' : 0 , 'mercedes' : 1},transforms=data_transform)\n","\n","dl_train=DataLoader(ds_train,batch_size=64,shuffle=True,num_workers=2)\n","dl_val=DataLoader(ds_val,batch_size=64,shuffle=True,num_workers=2)\n","\n","dataloaders_dict={'train':dl_train, 'val':dl_val}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5JvIABAhGEHg"},"source":["# Training loop"]},{"cell_type":"code","metadata":{"id":"wPT7Z2Ckn8Jh"},"source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","\n","                  outputs = model(inputs)\n","                  loss = criterion(outputs, labels)\n","\n","                  _, preds = torch.max(outputs, 1)\n","\n","                    # backward + optimize only if in training phase\n","                  if phase == 'train':\n","                    loss.backward()\n","                    optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.detach().item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","\n","    model.load_state_dict(best_model_wts)\n","    return model\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qulizcn5GJHs"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"W0NmRElAqupK"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","num_epochs=5\n","\n","vgg16 = models.vgg16(pretrained=True)\n","vgg16.classifier[6]=nn.Linear(4096,2)\n","vgg16.to(device)\n","optimizer = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Train and evaluate\n","model_ft, hist = train_model(vgg16, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)\n","\n","optimizer = optim.SGD(vgg16.parameters(), lr=0.0003, momentum=0.9)\n","model_ft, hist = train_model(vgg16, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q8sBZ8UQVHB3"},"source":["#Prediction and making submission"]},{"cell_type":"code","metadata":{"id":"7q6A7QYhGyou"},"source":["data_test_transform = transforms.Compose([\n","        transforms.Resize(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                             std=[0.229, 0.224, 0.225])\n","    ])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1kn-nhFqG5ZB"},"source":["vgg16.eval()\n","\n","A=[[i for i in range(10000)],['']*10000]\n","df=pd.DataFrame(A).transpose()\n","df.columns=['ImageID','bboxes']\n","i=0\n","for f in os.listdir('data/test/'):\n","  im=Image.open('data/test/'+f)\n","  tens=torch.reshape(data_test_transform(im),(1,3,224,224))\n","  inputs = tens.to(device)\n","  outputs = np.argmax(vgg16(inputs).detach().cpu().numpy())\n","  if outputs == 1:\n","    df.iloc[int(f.split('.')[0]),1]='mercedes'\n","  else:\n","    df.iloc[int(f.split('.')[0]),1]='redbull'\n","\n","df.to_csv('/content/drive/MyDrive/Colab Notebooks/aicrowd/f1/1 challange/submission.csv',index=False)"],"execution_count":null,"outputs":[]}]}